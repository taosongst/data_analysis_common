{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af9215ee",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-11-26T02:16:57.840742Z",
     "iopub.status.busy": "2021-11-26T02:16:57.838817Z",
     "iopub.status.idle": "2021-11-26T02:16:57.868132Z",
     "shell.execute_reply": "2021-11-26T02:16:57.868734Z"
    },
    "papermill": {
     "duration": 0.068156,
     "end_time": "2021-11-26T02:16:57.869034",
     "exception": false,
     "start_time": "2021-11-26T02:16:57.800878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML, Javascript\n",
    "\n",
    "# ----- Notebook Theme -----\n",
    "\n",
    "notebook_theme = 'carrot'\n",
    "color_maps = {'turquoise': ['#1abc9c', '#e8f8f5', '#d1f2eb', '#a3e4d7', '#76d7c4', '#48c9b0', '#1abc9c', '#17a589', '#148f77', '#117864', '#0e6251'], 'green': ['#16a085', '#e8f6f3', '#d0ece7', '#a2d9ce', '#73c6b6', '#45b39d', '#16a085', '#138d75', '#117a65', '#0e6655', '#0b5345'], 'emerald': ['#2ecc71', '#eafaf1', '#d5f5e3', '#abebc6', '#82e0aa', '#58d68d', '#2ecc71', '#28b463', '#239b56', '#1d8348', '#186a3b'], 'nephritis': ['#27ae60', '#e9f7ef', '#d4efdf', '#a9dfbf', '#7dcea0', '#52be80', '#27ae60', '#229954', '#1e8449', '#196f3d', '#145a32'], 'peter': ['#3498db', '#ebf5fb', '#d6eaf8', '#aed6f1', '#85c1e9', '#5dade2', '#3498db', '#2e86c1', '#2874a6', '#21618c', '#1b4f72'], 'belize': ['#2980b9', '#eaf2f8', '#d4e6f1', '#a9cce3', '#7fb3d5', '#5499c7', '#2980b9', '#2471a3', '#1f618d', '#1a5276', '#154360'], 'amethyst': ['#9b59b6', '#f5eef8', '#ebdef0', '#d7bde2', '#c39bd3', '#af7ac5', '#9b59b6', '#884ea0', '#76448a', '#633974', '#512e5f'], 'wisteria': ['#8e44ad', '#f4ecf7', '#e8daef', '#d2b4de', '#bb8fce', '#a569bd', '#8e44ad', '#7d3c98', '#6c3483', '#5b2c6f', '#4a235a'], 'wet': ['#34495e', '#ebedef', '#d6dbdf', '#aeb6bf', '#85929e', '#5d6d7e', '#34495e', '#2e4053', '#283747', '#212f3c', '#1b2631'], 'midnight': ['#2c3e50', '#eaecee', '#d5d8dc', '#abb2b9', '#808b96', '#566573', '#2c3e50', '#273746', '#212f3d', '#1c2833', '#17202a'], 'sunflower': ['#f1c40f', '#fef9e7', '#fcf3cf', '#f9e79f', '#f7dc6f', '#f4d03f', '#f1c40f', '#d4ac0d', '#b7950b', '#9a7d0a', '#7d6608'], 'orange': ['#f39c12', '#fef5e7', '#fdebd0', '#fad7a0', '#f8c471', '#f5b041', '#f39c12', '#d68910', '#b9770e', '#9c640c', '#7e5109'], 'carrot': ['#e67e22', '#fdf2e9', '#fae5d3', '#f5cba7', '#f0b27a', '#eb984e', '#e67e22', '#ca6f1e', '#af601a', '#935116', '#784212'], 'pumpkin': ['#d35400', '#fbeee6', '#f6ddcc', '#edbb99', '#e59866', '#dc7633', '#d35400', '#ba4a00', '#a04000', '#873600', '#6e2c00'], 'alizarin': ['#e74c3c', '#fdedec', '#fadbd8', '#f5b7b1', '#f1948a', '#ec7063', '#e74c3c', '#cb4335', '#b03a2e', '#943126', '#78281f'], 'pomegranate': ['#c0392b', '#f9ebea', '#f2d7d5', '#e6b0aa', '#d98880', '#cd6155', '#c0392b', '#a93226', '#922b21', '#7b241c', '#641e16'], 'clouds': ['#ecf0f1', '#fdfefe', '#fbfcfc', '#f7f9f9', '#f4f6f7', '#f0f3f4', '#ecf0f1', '#d0d3d4', '#b3b6b7', '#979a9a', '#7b7d7d'], 'silver': ['#bdc3c7', '#f8f9f9', '#f2f3f4', '#e5e7e9', '#d7dbdd', '#cacfd2', '#bdc3c7', '#a6acaf', '#909497', '#797d7f', '#626567'], 'concrete': ['#95a5a6', '#f4f6f6', '#eaeded', '#d5dbdb', '#bfc9ca', '#aab7b8', '#95a5a6', '#839192', '#717d7e', '#5f6a6a', '#4d5656'], 'asbestos': ['#7f8c8d', '#f2f4f4', '#e5e8e8', '#ccd1d1', '#b2babb', '#99a3a4', '#7f8c8d', '#707b7c', '#616a6b', '#515a5a', '#424949']}\n",
    "# color_maps = {'red': ['#f44336', '#ffebee', '#ffcdd2', '#ef9a9a', '#e57373', '#ef5350', '#f44336', '#e53935', '#d32f2f', '#c62828', '#b71c1c', '#ff8a80', '#ff5252', '#ff1744', '#d50000'], 'pink': ['#e91e63', '#fce4ec', '#f8bbd0', '#f48fb1', '#f06292', '#ec407a', '#e91e63', '#d81b60', '#c2185b', '#ad1457', '#880e4f', '#ff80ab', '#ff4081', '#f50057', '#c51162'], 'purple': ['#9c27b0', '#f3e5f5', '#e1bee7', '#ce93d8', '#ba68c8', '#ab47bc', '#9c27b0', '#8e24aa', '#7b1fa2', '#6a1b9a', '#4a148c', '#ea80fc', '#e040fb', '#d500f9', '#aa00ff'], 'deep': ['#673ab7', '#ede7f6', '#d1c4e9', '#b39ddb', '#9575cd', '#7e57c2', '#673ab7', '#5e35b1', '#512da8', '#4527a0', '#311b92', '#b388ff', '#7c4dff', '#651fff', '#6200ea', '#ff5722', '#fbe9e7', '#ffccbc', '#ffab91', '#ff8a65', '#ff7043', '#ff5722', '#f4511e', '#e64a19', '#d84315', '#bf360c', '#ff9e80', '#ff6e40', '#ff3d00', '#dd2c00'], 'indigo': ['#3f51b5', '#e8eaf6', '#c5cae9', '#9fa8da', '#7986cb', '#5c6bc0', '#3f51b5', '#3949ab', '#303f9f', '#283593', '#1a237e', '#8c9eff', '#536dfe', '#3d5afe', '#304ffe'], 'blue': ['#2196f3', '#e3f2fd', '#bbdefb', '#90caf9', '#64b5f6', '#42a5f5', '#2196f3', '#1e88e5', '#1976d2', '#1565c0', '#0d47a1', '#82b1ff', '#448aff', '#2979ff', '#2962ff', '#607d8b', '#eceff1', '#cfd8dc', '#b0bec5', '#90a4ae', '#78909c', '#607d8b', '#546e7a', '#455a64', '#37474f', '#263238'], 'light': ['#03a9f4', '#e1f5fe', '#b3e5fc', '#81d4fa', '#4fc3f7', '#29b6f6', '#03a9f4', '#039be5', '#0288d1', '#0277bd', '#01579b', '#80d8ff', '#40c4ff', '#00b0ff', '#0091ea', '#8bc34a', '#f1f8e9', '#dcedc8', '#c5e1a5', '#aed581', '#9ccc65', '#8bc34a', '#7cb342', '#689f38', '#558b2f', '#33691e', '#ccff90', '#b2ff59', '#76ff03', '#64dd17'], 'cyan': ['#00bcd4', '#e0f7fa', '#b2ebf2', '#80deea', '#4dd0e1', '#26c6da', '#00bcd4', '#00acc1', '#0097a7', '#00838f', '#006064', '#84ffff', '#18ffff', '#00e5ff', '#00b8d4'], 'teal': ['#009688', '#e0f2f1', '#b2dfdb', '#80cbc4', '#4db6ac', '#26a69a', '#009688', '#00897b', '#00796b', '#00695c', '#004d40', '#a7ffeb', '#64ffda', '#1de9b6', '#00bfa5'], 'green': ['#4caf50', '#e8f5e9', '#c8e6c9', '#a5d6a7', '#81c784', '#66bb6a', '#4caf50', '#43a047', '#388e3c', '#2e7d32', '#1b5e20', '#b9f6ca', '#69f0ae', '#00e676', '#00c853'], 'lime': ['#cddc39', '#f9fbe7', '#f0f4c3', '#e6ee9c', '#dce775', '#d4e157', '#cddc39', '#c0ca33', '#afb42b', '#9e9d24', '#827717', '#f4ff81', '#eeff41', '#c6ff00', '#aeea00'], 'yellow': ['#ffeb3b', '#fffde7', '#fff9c4', '#fff59d', '#fff176', '#ffee58', '#ffeb3b', '#fdd835', '#fbc02d', '#f9a825', '#f57f17', '#ffff8d', '#ffff00', '#ffea00', '#ffd600'], 'amber': ['#ffc107', '#fff8e1', '#ffecb3', '#ffe082', '#ffd54f', '#ffca28', '#ffc107', '#ffb300', '#ffa000', '#ff8f00', '#ff6f00', '#ffe57f', '#ffd740', '#ffc400', '#ffab00'], 'orange': ['#ff9800', '#fff3e0', '#ffe0b2', '#ffcc80', '#ffb74d', '#ffa726', '#ff9800', '#fb8c00', '#f57c00', '#ef6c00', '#e65100', '#ffd180', '#ffab40', '#ff9100', '#ff6d00'], 'brown': ['#795548', '#efebe9', '#d7ccc8', '#bcaaa4', '#a1887f', '#8d6e63', '#795548', '#6d4c41', '#5d4037', '#4e342e', '#3e2723'], 'grey': ['#9e9e9e', '#fafafa', '#f5f5f5', '#eeeeee', '#e0e0e0', '#bdbdbd', '#9e9e9e', '#757575', '#616161', '#424242', '#212121'], 'white': ['#ffffff'], 'black': ['#000000']}\n",
    "\n",
    "color_maps = {i: color_maps[i] for i in color_maps if i not in ['clouds', 'silver', 'concrete', 'asbestos', 'wet asphalt', 'midnight blue', 'wet']}\n",
    "\n",
    "CMAP = 'Oranges'\n",
    "prompt = '#1DBCCD'\n",
    "main_color = '#E58F65' # color_maps[notebook_theme]\n",
    "strong_main_color = '#EB9514' # = color_maps[notebook_theme] \n",
    "custom_colors = [strong_main_color, main_color]\n",
    "\n",
    "# ----- Notebook Theme -----\n",
    "\n",
    "html_contents =\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "    <head>\n",
    "        <link rel=\"stylesheet\" href=\"https://www.w3schools.com/w3css/4/w3.css\">\n",
    "        <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/css?family=Raleway\">\n",
    "        <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/css?family=Oswald\">\n",
    "        <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/css?family=Open Sans\">\n",
    "        <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css\">\n",
    "        <style>\n",
    "        .title-section{\n",
    "            font-family: \"Oswald\", Arial, sans-serif;\n",
    "            font-weight: bold;\n",
    "            color: \"#6A8CAF\";\n",
    "            letter-spacing: 6px;\n",
    "        }\n",
    "        hr { border: 1px solid #E58F65 !important;\n",
    "             color: #E58F65 !important;\n",
    "             background: #E58F65 !important;\n",
    "           }\n",
    "        body {\n",
    "            font-family: \"Open Sans\", sans-serif;\n",
    "            }        \n",
    "        </style>\n",
    "    </head>    \n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "HTML(html_contents)\n",
    "import os\n",
    "if not os.path.exists(\"../input/g-research-crypto-forecasting/\"): os.chdir('/t/Datasets/kaggle_crypto/internal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3235a88",
   "metadata": {
    "_cell_guid": "42a2c92b-00e6-4c13-b99e-408266d1b964",
    "_uuid": "9b3904ae-5fd7-432b-a10a-1a2446fbcc4b",
    "papermill": {
     "duration": 0.028562,
     "end_time": "2021-11-26T02:16:57.925959",
     "exception": false,
     "start_time": "2021-11-26T02:16:57.897397",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<br><br>\n",
    "<div>    \n",
    "<!--     <div style = \"float:left; width:55%; overflow:hidden;\">         -->\n",
    "        <center><img src=\"https://i.ibb.co/hHpTy3c/g-research-logo6.png\" style = \"max-height:300px;\"></center> \n",
    "<!--     </div> -->\n",
    "<!--     <div style = \"float:right; width:35%; overflow:hidden;\"> -->\n",
    "<!--         <img src=\"img/meditation/Meditation3.gif\">  -->\n",
    "<!--     </div> -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb308b72",
   "metadata": {
    "_cell_guid": "3208562a-4f7a-45d5-b8e2-67da427cd906",
    "_uuid": "d7276e81-829f-4be5-967d-0a641fb1adbf",
    "papermill": {
     "duration": 0.028151,
     "end_time": "2021-11-26T02:16:57.982136",
     "exception": false,
     "start_time": "2021-11-26T02:16:57.953985",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117d8155",
   "metadata": {
    "_cell_guid": "241ce292-edca-4688-a665-c6321e80b438",
    "_uuid": "79576405-5d2f-465f-bb01-10eee623172c",
    "papermill": {
     "duration": 0.029518,
     "end_time": "2021-11-26T02:16:58.040280",
     "exception": false,
     "start_time": "2021-11-26T02:16:58.010762",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div>    \n",
    "    <div style = \"float:left; width:55%; overflow:hidden;\">        \n",
    "        <br><br><br><br>        \n",
    "        <span style = \"float:right;\">\n",
    "        <h2>Reinforcement Learning Starter</h2>\n",
    "        <p>G-Research Crypto Forecasting Competition</p>\n",
    "        <br>\n",
    "        <b></b>\n",
    "        <b>\n",
    "        - 🌎 <a href=\"https://www.kaggle.com/c/g-research-crypto-forecasting/discussion/284903\">Discussion Thread</a>\n",
    "        <br>\n",
    "        - 🇰 <a href=\"https://www.kaggle.com/c/g-research-crypto-forecasting/discussion/285726\">The dataset</a>\n",
    "        </b>            \n",
    "        </span>\n",
    "    </div>\n",
    "    <div style=\"float:right; width:35%; max-height:300px; overflow: hidden;\">        \n",
    "        <img src=\"https://i.ibb.co/9YFyhT8/Bitcoin2.gif\" style = \"max-height: 300px;\">         \n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5239bc2",
   "metadata": {
    "_cell_guid": "ca79faf7-ca73-4e9b-8552-be96bdc881f9",
    "_uuid": "4e428101-c977-488b-aa10-fe96d228224f",
    "papermill": {
     "duration": 0.027208,
     "end_time": "2021-11-26T02:16:58.095248",
     "exception": false,
     "start_time": "2021-11-26T02:16:58.068040",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span id=\"introduction\"></span>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d7f8bf",
   "metadata": {
    "_cell_guid": "8af163ff-915a-4fae-aefe-6447e64952e5",
    "_uuid": "b328cc9e-a536-4347-beed-d033e9f5ac6a",
    "papermill": {
     "duration": 0.027055,
     "end_time": "2021-11-26T02:16:58.149762",
     "exception": false,
     "start_time": "2021-11-26T02:16:58.122707",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    ">### Reinforcement Learning Starter\n",
    ">This is a simple starter notebook for Kaggle's Crypto Comp showing purged group timeseries KFold with extra data. Purged Times Series is explained [here][2]. There are many configuration variables below to allow you to experiment. Use either CPU or GPU. You can control which years are loaded, which neural networks are used, and whether to use feature engineering. You can experiment with different data preprocessing, model hyperparameters, loss, and number of seeds to ensemble. The extra datasets contain the full history of the assets at the same format of the competition, so you can input that into your model too.\n",
    ">\n",
    ">This notebook follows the ideas presented in my \"Initial Thoughts\" [here][1].\n",
    "\n",
    "[1]: https://www.kaggle.com/c/g-research-crypto-forecasting/discussion/284903\n",
    "[2]: https://www.kaggle.com/yamqwe/let-s-talk-validation-grouptimeseriessplit\n",
    "[3]: https://www.kaggle.com/cdeotte/triple-stratified-kfold-with-tfrecords\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>References:</b>\n",
    "<ul>\n",
    "    <li><a href = \"https://www.kaggle.com/c/g-research-crypto-forecasting/discussion/285726\">Dataset Thread</a></li>\n",
    "    <li><a href = \"https://www.kaggle.com/c/g-research-crypto-forecasting/discussion/284903\">Initial Thoughts Thread\n",
    "</a></li>\n",
    "    <li><a href = \"https://www.kaggle.com/yamqwe/let-s-talk-validation-grouptimeseriessplit\">Validation Thread\n",
    "</a></li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c668e4d0",
   "metadata": {
    "papermill": {
     "duration": 0.027125,
     "end_time": "2021-11-26T02:16:58.204586",
     "exception": false,
     "start_time": "2021-11-26T02:16:58.177461",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "____\n",
    "\n",
    "#### <center>All notebooks in the series 👇</center>\n",
    "\n",
    "| CV + Model | Hyperparam Optimization  | Time Series Models | Feature Engineering |\n",
    "| --- | --- | --- | --- |\n",
    "| [Neural Network Starter](https://www.kaggle.com/yamqwe/purgedgrouptimeseries-cv-with-extra-data-nn) | [MLP + AE](https://www.kaggle.com/yamqwe/bottleneck-encoder-mlp-keras-tuner)        | [LSTM](https://www.kaggle.com/yamqwe/time-series-modeling-lstm) | [Technical Analysis #1](https://www.kaggle.com/yamqwe/crypto-prediction-technical-analysis-features) |\n",
    "| [LightGBM Starter](https://www.kaggle.com/yamqwe/purgedgrouptimeseries-cv-with-extra-data-lgbm)     | [LightGBM](https://www.kaggle.com/yamqwe/purged-time-series-cv-lightgbm-optuna)     | [Wavenet](https://www.kaggle.com/yamqwe/time-series-modeling-wavenet)  | [Technical Analysis #2](https://www.kaggle.com/yamqwe/crypto-prediction-technical-analysis-feats-2) |\n",
    "| [Catboost Starter](https://www.kaggle.com/yamqwe/purgedgrouptimeseries-cv-extra-data-catboost)      | [Catboost](https://www.kaggle.com/yamqwe/purged-time-series-cv-catboost-gpu-optuna) | [Multivariate-Transformer [written from scratch]](https://www.kaggle.com/yamqwe/time-series-modeling-multivariate-transformer) | [Time Series Agg](https://www.kaggle.com/yamqwe/features-all-time-series-aggregations-ever) | \n",
    "| [XGBoost Starter](https://www.kaggle.com/yamqwe/xgb-extra-data)                                            | [XGboost](https://www.kaggle.com/yamqwe/purged-time-series-cv-xgboost-gpu-optuna) | [N-BEATS](https://www.kaggle.com/yamqwe/crypto-forecasting-n-beats) |  [Neutralization](https://www.kaggle.com/yamqwe/g-research-avoid-overfit-feature-neutralization/) |\n",
    "| [Supervised AE [Janestreet 1st]](https://www.kaggle.com/yamqwe/1st-place-of-jane-street-adapted-to-crypto) | [Supervised AE [Janestreet 1st]](https://www.kaggle.com/yamqwe/1st-place-of-jane-street-keras-tuner) | [DeepAR](https://www.kaggle.com/yamqwe/probabilistic-forecasting-deepar/) | [Quant's Volatility Features](https://www.kaggle.com/yamqwe/crypto-prediction-volatility-features) |\n",
    "| [Transformer)](https://www.kaggle.com/yamqwe/let-s-test-a-transformer)                                     | [Transformer](https://www.kaggle.com/yamqwe/sh-tcoins-transformer-baseline)  |  | ⏳Target Engineering |\n",
    "| [TabNet Starter](https://www.kaggle.com/yamqwe/tabnet-cv-extra-data)                                       |  |  |⏳Fourier Analysis | \n",
    "| [Reinforcement Learning (PPO) Starter](https://www.kaggle.com/yamqwe/g-research-reinforcement-learning-starter) | | | ⏳Wavelets | \n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84379890",
   "metadata": {
    "_cell_guid": "3208562a-4f7a-45d5-b8e2-67da427cd906",
    "_uuid": "d7276e81-829f-4be5-967d-0a641fb1adbf",
    "papermill": {
     "duration": 0.027165,
     "end_time": "2021-11-26T02:16:58.259881",
     "exception": false,
     "start_time": "2021-11-26T02:16:58.232716",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span class=\"title-section w3-xxlarge\" id=\"outline\">Table Of Content 📑</span>\n",
    "<hr >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73915a0",
   "metadata": {
    "_cell_guid": "d70815a1-3398-43b2-be85-2230fffd89a9",
    "_uuid": "e9b980c5-036c-4e25-992b-115169a95ba4",
    "papermill": {
     "duration": 0.027034,
     "end_time": "2021-11-26T02:16:58.314919",
     "exception": false,
     "start_time": "2021-11-26T02:16:58.287885",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Table Of Content\n",
    "\n",
    "1. [📝 Introduction](#introduction)\n",
    "\n",
    "2. [📑 Table Of Content](#outline) \n",
    "\n",
    "3. [🤿 Diving into the Data](#diving) \n",
    "\n",
    "4. [💾 Installations](#imports) \n",
    "\n",
    "5. [📚 Imports](#imports) \n",
    "\n",
    "6. [🎚️ Configurations](#config) \n",
    "\n",
    "7. [🗃️ Data Loading](#loading)  \n",
    "\n",
    "8. [⚙️ Defining the GYM Environment](#modelconf)\n",
    "\n",
    "9. [🏋️ Reinforcement Learning](#training)\n",
    "\n",
    "10. [🇰 Submit To Kaggle](#submit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe275eb",
   "metadata": {
    "_cell_guid": "310c5bce-3fab-4a82-b70e-d5e8a0e5e594",
    "_uuid": "ce509f90-2ae9-4ea3-94ad-39479b72ca12",
    "papermill": {
     "duration": 0.027087,
     "end_time": "2021-11-26T02:16:58.369481",
     "exception": false,
     "start_time": "2021-11-26T02:16:58.342394",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span class=\"title-section w3-xxlarge\" id=\"outline\">Diving into the Data 🤿</span>\n",
    "<hr >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29b5533",
   "metadata": {
    "_cell_guid": "ca6da936-954f-427b-af0c-f04517c4d4ed",
    "_uuid": "a91494a0-a071-49e5-bcc0-9c7b7566ad75",
    "papermill": {
     "duration": 0.02724,
     "end_time": "2021-11-26T02:16:58.424167",
     "exception": false,
     "start_time": "2021-11-26T02:16:58.396927",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "#### **<span>Dataset Structure</span>**\n",
    "\n",
    "> **train.csv** - The training set\n",
    "> \n",
    "> 1.  timestamp - A timestamp for the minute covered by the row.\n",
    "> 2.  Asset_ID - An ID code for the cryptoasset.\n",
    "> 3.  Count - The number of trades that took place this minute.\n",
    "> 4.  Open - The USD price at the beginning of the minute.\n",
    "> 5.  High - The highest USD price during the minute.\n",
    "> 6.  Low - The lowest USD price during the minute.\n",
    "> 7.  Close - The USD price at the end of the minute.\n",
    "> 8.  Volume - The number of cryptoasset u units traded during the minute.\n",
    "> 9.  VWAP - The volume-weighted average price for the minute.\n",
    "> 10. Target - 15 minute residualized returns. See the 'Prediction and Evaluation section of this notebook for details of how the target is calculated.\n",
    "> 11. Weight - Weight, defined by the competition hosts [here](https://www.kaggle.com/cstein06/tutorial-to-the-g-research-crypto-competition)\n",
    "> 12. Asset_Name - Human readable Asset name.\n",
    "> \n",
    ">\n",
    "> **example_test.csv** - An example of the data that will be delivered by the time series API.\n",
    "> \n",
    "> **example_sample_submission.csv** - An example of the data that will be delivered by the time series API. The data is just copied from train.csv.\n",
    "> \n",
    "> **asset_details.csv** - Provides the real name and of the cryptoasset for each Asset_ID and the weight each cryptoasset receives in the metric.\n",
    "> \n",
    "> **supplemental_train.csv** - After the submission period is over this file's data will be replaced with cryptoasset prices from the submission period. In the Evaluation phase, the train, train supplement, and test set will be contiguous in time, apart from any missing data. The current copy, which is just filled approximately the right amount of data from train.csv is provided as a placeholder.\n",
    ">\n",
    "> - 📌 There are 14 coins in the dataset\n",
    ">\n",
    "> - 📌 There are 4 years  in the [full] dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7917a33b",
   "metadata": {
    "_cell_guid": "75405d52-594f-4791-a45a-16354bc24cfa",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "775496bb-f633-46f4-a642-10e6cd29c1bb",
    "execution": {
     "iopub.execute_input": "2021-11-26T02:16:58.483016Z",
     "iopub.status.busy": "2021-11-26T02:16:58.482258Z",
     "iopub.status.idle": "2021-11-26T02:16:58.496498Z",
     "shell.execute_reply": "2021-11-26T02:16:58.497055Z",
     "shell.execute_reply.started": "2021-10-29T12:52:34.274423Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.045642,
     "end_time": "2021-11-26T02:16:58.497231",
     "exception": false,
     "start_time": "2021-11-26T02:16:58.451589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "div #notebook {\n",
       "background-color: white;\n",
       "font-family: 'Open Sans', Helvetica, sans-serif;\n",
       "line-height: 20px;\n",
       "}\n",
       "\n",
       "#notebook-container {\n",
       "margin-top: 2em;\n",
       "padding-top: 2em;\n",
       "border-top: 4px solid #E58F65; /* light orange */\n",
       "-webkit-box-shadow: 0px 0px 8px 2px rgba(224, 212, 226, 0.5); /* pink */\n",
       "    box-shadow: 0px 0px 8px 2px rgba(224, 212, 226, 0.5); /* pink */\n",
       "}\n",
       "\n",
       "div .input {\n",
       "margin-bottom: 1em;\n",
       "}\n",
       "\n",
       ".rendered_html h1, .rendered_html h2, .rendered_html h3, .rendered_html h4, .rendered_html h5, .rendered_html h6 {\n",
       "color: #E58F65; /* light orange */\n",
       "font-weight: 600;\n",
       "}\n",
       "\n",
       ".rendered_html code {\n",
       "    background-color: #efefef; /* light gray */\n",
       "}\n",
       "\n",
       ".CodeMirror {\n",
       "color: #8c8c8c; /* dark gray */\n",
       "padding: 0.7em;\n",
       "}\n",
       "\n",
       "div.input_area {\n",
       "border: none;\n",
       "    background-color: rgba(229, 143, 101, 0.1); /* rgba(229, 143, 101, 0.1); light orange [exactly #E58F65] */\n",
       "    border-top: 2px solid #E58F65; /* light orange */\n",
       "}\n",
       "\n",
       "div.input_prompt {\n",
       "color: #1DBCCD; /* light blue */\n",
       "}\n",
       "\n",
       "div.output_prompt {\n",
       "color: #EB9514; /* strong orange */\n",
       "}\n",
       "\n",
       "div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before {\n",
       "background: #E58F65; /* light orange */\n",
       "}\n",
       "\n",
       "div.cell.selected, div.cell.selected.jupyter-soft-selected {\n",
       "    border-color: #E58F65; /* light orange */\n",
       "}\n",
       "\n",
       ".edit_mode div.cell.selected:before {\n",
       "background: #E58F65; /* light orange */\n",
       "}\n",
       "\n",
       ".edit_mode div.cell.selected {\n",
       "border-color: #E58F65; /* light orange */\n",
       "\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "css_file = '''\n",
    "div #notebook {\n",
    "background-color: white;\n",
    "font-family: 'Open Sans', Helvetica, sans-serif;\n",
    "line-height: 20px;\n",
    "}\n",
    "\n",
    "#notebook-container {\n",
    "margin-top: 2em;\n",
    "padding-top: 2em;\n",
    "border-top: 4px solid %s; /* light orange */\n",
    "-webkit-box-shadow: 0px 0px 8px 2px rgba(224, 212, 226, 0.5); /* pink */\n",
    "    box-shadow: 0px 0px 8px 2px rgba(224, 212, 226, 0.5); /* pink */\n",
    "}\n",
    "\n",
    "div .input {\n",
    "margin-bottom: 1em;\n",
    "}\n",
    "\n",
    ".rendered_html h1, .rendered_html h2, .rendered_html h3, .rendered_html h4, .rendered_html h5, .rendered_html h6 {\n",
    "color: %s; /* light orange */\n",
    "font-weight: 600;\n",
    "}\n",
    "\n",
    ".rendered_html code {\n",
    "    background-color: #efefef; /* light gray */\n",
    "}\n",
    "\n",
    ".CodeMirror {\n",
    "color: #8c8c8c; /* dark gray */\n",
    "padding: 0.7em;\n",
    "}\n",
    "\n",
    "div.input_area {\n",
    "border: none;\n",
    "    background-color: %s; /* rgba(229, 143, 101, 0.1); light orange [exactly #E58F65] */\n",
    "    border-top: 2px solid %s; /* light orange */\n",
    "}\n",
    "\n",
    "div.input_prompt {\n",
    "color: %s; /* light blue */\n",
    "}\n",
    "\n",
    "div.output_prompt {\n",
    "color: %s; /* strong orange */\n",
    "}\n",
    "\n",
    "div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before {\n",
    "background: %s; /* light orange */\n",
    "}\n",
    "\n",
    "div.cell.selected, div.cell.selected.jupyter-soft-selected {\n",
    "    border-color: %s; /* light orange */\n",
    "}\n",
    "\n",
    ".edit_mode div.cell.selected:before {\n",
    "background: %s; /* light orange */\n",
    "}\n",
    "\n",
    ".edit_mode div.cell.selected {\n",
    "border-color: %s; /* light orange */\n",
    "\n",
    "}\n",
    "'''\n",
    "def to_rgb(h): return tuple(int(h[i:i+2], 16) for i in (0, 2, 4))\n",
    "main_color_rgba = 'rgba(%s, %s, %s, 0.1)' % (to_rgb(main_color[1:])[0], to_rgb(main_color[1:])[1], to_rgb(main_color[1:])[2])\n",
    "open('notebook.css', 'w').write(css_file % (main_color, main_color, main_color_rgba, main_color,  prompt, strong_main_color, main_color, main_color, main_color, main_color))\n",
    "from IPython.core.display import display, HTML, Javascript\n",
    "def nb(): return HTML(\"<style>\" + open(\"notebook.css\", \"r\").read() + \"</style>\")\n",
    "nb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b04176cf",
   "metadata": {
    "_cell_guid": "75d3e80e-0c31-48f5-88dd-5b6a3c79cf38",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "968efaca-ede8-4817-b3aa-baedaba3205e",
    "execution": {
     "iopub.execute_input": "2021-11-26T02:16:58.557289Z",
     "iopub.status.busy": "2021-11-26T02:16:58.556571Z",
     "iopub.status.idle": "2021-11-26T02:16:58.562893Z",
     "shell.execute_reply": "2021-11-26T02:16:58.563435Z",
     "shell.execute_reply.started": "2021-10-29T12:52:34.293927Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.037951,
     "end_time": "2021-11-26T02:16:58.563636",
     "exception": false,
     "start_time": "2021-11-26T02:16:58.525685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "div #notebook {\n",
       "background-color: white;\n",
       "font-family: 'Open Sans', Helvetica, sans-serif;\n",
       "line-height: 20px;\n",
       "}\n",
       "\n",
       "#notebook-container {\n",
       "margin-top: 2em;\n",
       "padding-top: 2em;\n",
       "border-top: 4px solid #E58F65; /* light orange */\n",
       "-webkit-box-shadow: 0px 0px 8px 2px rgba(224, 212, 226, 0.5); /* pink */\n",
       "    box-shadow: 0px 0px 8px 2px rgba(224, 212, 226, 0.5); /* pink */\n",
       "}\n",
       "\n",
       "div .input {\n",
       "margin-bottom: 1em;\n",
       "}\n",
       "\n",
       ".rendered_html h1, .rendered_html h2, .rendered_html h3, .rendered_html h4, .rendered_html h5, .rendered_html h6 {\n",
       "color: #E58F65; /* light orange */\n",
       "font-weight: 600;\n",
       "}\n",
       "\n",
       ".rendered_html code {\n",
       "    background-color: #efefef; /* light gray */\n",
       "}\n",
       "\n",
       ".CodeMirror {\n",
       "color: #8c8c8c; /* dark gray */\n",
       "padding: 0.7em;\n",
       "}\n",
       "\n",
       "div.input_area {\n",
       "border: none;\n",
       "    background-color: rgba(229, 143, 101, 0.1); /* rgba(229, 143, 101, 0.1); light orange [exactly #E58F65] */\n",
       "    border-top: 2px solid #E58F65; /* light orange */\n",
       "}\n",
       "\n",
       "div.input_prompt {\n",
       "color: #1DBCCD; /* light blue */\n",
       "}\n",
       "\n",
       "div.output_prompt {\n",
       "color: #EB9514; /* strong orange */\n",
       "}\n",
       "\n",
       "div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before {\n",
       "background: #E58F65; /* light orange */\n",
       "}\n",
       "\n",
       "div.cell.selected, div.cell.selected.jupyter-soft-selected {\n",
       "    border-color: #E58F65; /* light orange */\n",
       "}\n",
       "\n",
       ".edit_mode div.cell.selected:before {\n",
       "background: #E58F65; /* light orange */\n",
       "}\n",
       "\n",
       ".edit_mode div.cell.selected {\n",
       "border-color: #E58F65; /* light orange */\n",
       "\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML, Javascript\n",
    "# def nb(): return HTML(\"<style>\" + open(\"../input/starter-utils/css_oranges.css\", \"r\").read() + \"</style>\")\n",
    "def nb(): return HTML(\"<style>\" + open(\"notebook.css\", \"r\").read() + \"</style>\")\n",
    "nb()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a203efad",
   "metadata": {
    "papermill": {
     "duration": 0.028328,
     "end_time": "2021-11-26T02:16:58.620990",
     "exception": false,
     "start_time": "2021-11-26T02:16:58.592662",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span class=\"title-section w3-xxlarge\" id=\"codebook\">Reinforcement Learning Starter</span>\n",
    "This is a simple starter notebook for Kaggle's Crypto Comp showing the usage of reinforcement learning for crypto trading. It uses an up-to-date (auto-updating daily) dataset for all assets discussed [here][4].  There are many configuration variables below to allow you to experiment. Use a different stable-baseline agent. You can control which years are loaded, which models are used, and whether to use feature engineering. You can experiment with different data preprocessing, model hyperparameters, losses, and number of seeds to ensemble. The extra datasets contain the full history of the assets at the same format of the competition, so you can input that into your model too.\n",
    "\n",
    "This notebook follows the ideas presented in my \"Initial Thoughts\" [here][1]. Some code sections have been reused from Chris' great notebook series on SIIM ISIC melanoma detection competition [here][3]\n",
    "\n",
    "____\n",
    "**Credits:**\n",
    "\n",
    "Notebook this is baseline is based on: \n",
    "- [Jane Street: Deep Reinforcement Learning Approach](https://www.kaggle.com/gogo827jz/jane-street-deep-reinforcement-learning-approach) by Yirun Zhang\n",
    "- [🤖 Deep RL: PPO2 with GPU Baseline 🦾](https://www.kaggle.com/metathesis/deep-rl-ppo2-with-gpu-baseline) by Jim Eric Skogman\n",
    "- [Triple Stratified Kfold with TFrecords](https://www.kaggle.com/cdeotte/triple-stratified-kfold-with-tfrecords) by Chris Deotte\n",
    "\n",
    "If you find this notebook useful, don't forget about them and drop them some upvotes! \n",
    "They've all earned it!\n",
    "____\n",
    "\n",
    "\n",
    "[1]: https://www.kaggle.com/c/g-research-crypto-forecasting/discussion/284903\n",
    "[2]: https://www.kaggle.com/yamqwe/let-s-talk-validation-grouptimeseriessplit\n",
    "[3]: https://www.kaggle.com/cdeotte/triple-stratified-kfold-with-tfrecords\n",
    "[4]: https://www.kaggle.com/c/g-research-crypto-forecasting/discussion/285726"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceb9b33",
   "metadata": {
    "papermill": {
     "duration": 0.028336,
     "end_time": "2021-11-26T02:16:58.678056",
     "exception": false,
     "start_time": "2021-11-26T02:16:58.649720",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span class=\"title-section w3-xxlarge\" id=\"codebook\">Why Reinforcement Learning?</span>\n",
    "\n",
    "\n",
    "> Credit: Huge credit to the original kaggle learn tutorial for providing the skeleton for this intro\n",
    "\n",
    "\n",
    "### Introduction\n",
    "So far, on this competition, most notebooks only implemented supervised learning solutions. These solutions have relied on detailed information about how to trade the assets. \n",
    "However, do to the nature of financial trading [specifically speaking: No \"clearly defined\" target]. A reinforcement learning approach might fit the problem of cryptocurrency trading well.\n",
    "\n",
    "In this baseline notebook, I'll try and use reinforcement learning to build an intelligent agent without the use of a supervised target. Instead, we will gradually refine the agent's strategy over time, simply by trading the assets historicly  trying to maximize the the prediction of the target.\n",
    "\n",
    "Since this is a starter notebook, we won't be able to explore this complex field in detail, but I hope to share about the big picture and explore some code that you can then use and improve yourself.\n",
    "\n",
    "### From Supervised Neural Networks to Deep Reinforcement Learning\n",
    "\n",
    "It's difficult to come up with a perfect heuristic. Improving the heuristic generally entails trading the assets many times, to determine specific cases where the agent could have made better choices. And, it can prove challenging to interpret what exactly is going wrong, and ultimately to fix old mistakes without accidentally introducing new ones.\n",
    "\n",
    "Wouldn't it be much easier if we had a more systematic way of improving the agent with trading experience?\n",
    "We'll just replace the supervised target with a neural network to estimate what should have been the target at the current observation state. \n",
    "The network accepts the current market features as input. And, it outputs a value that is then used for trading.\n",
    "\n",
    "This way, to encode a trading strategy, we need only amend the weights of the network so that for every possible market condition, it assigns higher probabilities to better trades.\n",
    "At least in theory, that's our goal. In practice, we won't actually check if that's the case -- since remember that there are infinite possibilies for market conditions.\n",
    "\n",
    "\n",
    "### Reinforcement Learning\n",
    "There are many different reinforcement learning algorithms, such as DQN, A2C, and PPO, among others. All of these algorithms use a similar process to produce an agent:\n",
    "\n",
    "Initially, the weights are set to random values.\n",
    "As the agent plays the game [Or trades the assets], the algorithm continually tries out new values for the weights, to see how the cumulative reward is affected, on average. Over time, after playing many games, we get a good idea of how the weights affect cumulative reward, and the algorithm settles towards weights that performed better.\n",
    "\n",
    "Of course, we have glossed over the details here, and there's a lot of complexity involved in this process. For now, we focus on the big picture!\n",
    "This way, we'll end up with an agent that tries to win the game (so it gets the final reward of +1, and avoids the -1 and -10) and tries to make the game last as long as possible (so that it collects the 1/42 bonus as many times as it can).\n",
    "You might argue that it doesn't really make sense to want the game to last as long as possible -- this might result in a very inefficient agent that doesn't play obvious winning moves early in gameplay. And, your intuition would be correct -- this will make the agent take longer to play a winning move! The reason we include the 1/42 bonus is to help the algorithms we'll use to converge better. Further discussion is outside of the scope of this course, but you can learn more by reading about the \"temporal credit assignment problem\" and \"reward shaping\".\n",
    "In the next section, we'll use the Proximal Policy Optimization (PPO) algorithm to create an agent.\n",
    "\n",
    "### Code\n",
    "There are a lot of great implementations of reinforcement learning algorithms online. In this course, we'll use Stable Baselines.\n",
    "Currently, Stable Baselines is not yet compatible with TensorFlow 2.0. So, we begin by downgrading to TensorFlow 1.0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7560a95",
   "metadata": {
    "papermill": {
     "duration": 0.028337,
     "end_time": "2021-11-26T02:16:58.735044",
     "exception": false,
     "start_time": "2021-11-26T02:16:58.706707",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span class=\"title-section w3-xxlarge\" id=\"install\">Installations 💾</span>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a748b24c",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-11-26T02:16:58.795767Z",
     "iopub.status.busy": "2021-11-26T02:16:58.794935Z",
     "iopub.status.idle": "2021-11-26T02:19:41.102411Z",
     "shell.execute_reply": "2021-11-26T02:19:41.101688Z",
     "shell.execute_reply.started": "2021-11-08T05:45:36.3458Z"
    },
    "papermill": {
     "duration": 162.338833,
     "end_time": "2021-11-26T02:19:41.102580",
     "exception": false,
     "start_time": "2021-11-26T02:16:58.763747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==1.15.0\r\n",
      "  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 412.3 MB 19 kB/s \r\n",
      "\u001b[?25hCollecting astor>=0.6.0\r\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\r\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.0) (0.14.0)\r\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.0) (3.19.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.1.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.0) (0.2.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.12.1)\r\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.38.1)\r\n",
      "Collecting gast==0.2.2\r\n",
      "  Downloading gast-0.2.2.tar.gz (10 kB)\r\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.16.0)\r\n",
      "Collecting tensorflow-estimator==1.15.1\r\n",
      "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 503 kB 39.6 MB/s \r\n",
      "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\r\n",
      "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 37.6 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.1.2)\r\n",
      "Collecting keras-applications>=1.0.8\r\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 50 kB 5.0 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.0) (0.37.0)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.0) (3.3.0)\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.19.5)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (3.1.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.4)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (58.0.4)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (2.0.1)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (4.8.1)\r\n",
      "Requirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.0) (1.5.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.10.0.2)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.5.0)\r\n",
      "Building wheels for collected packages: gast\r\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=15a006b9bcbb494c61c661ccadb1e35ac38f07753777bc90e46d32bc5cbe928e\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\r\n",
      "Successfully built gast\r\n",
      "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, astor, tensorflow\r\n",
      "  Attempting uninstall: tensorflow-estimator\r\n",
      "    Found existing installation: tensorflow-estimator 2.6.0\r\n",
      "    Uninstalling tensorflow-estimator-2.6.0:\r\n",
      "      Successfully uninstalled tensorflow-estimator-2.6.0\r\n",
      "  Attempting uninstall: tensorboard\r\n",
      "    Found existing installation: tensorboard 2.5.0\r\n",
      "    Uninstalling tensorboard-2.5.0:\r\n",
      "      Successfully uninstalled tensorboard-2.5.0\r\n",
      "  Attempting uninstall: gast\r\n",
      "    Found existing installation: gast 0.4.0\r\n",
      "    Uninstalling gast-0.4.0:\r\n",
      "      Successfully uninstalled gast-0.4.0\r\n",
      "  Attempting uninstall: tensorflow\r\n",
      "    Found existing installation: tensorflow 2.6.0\r\n",
      "    Uninstalling tensorflow-2.6.0:\r\n",
      "      Successfully uninstalled tensorflow-2.6.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-io 0.18.0 requires tensorflow-io-gcs-filesystem==0.18.0, which is not installed.\r\n",
      "explainable-ai-sdk 1.3.2 requires xai-image-widget, which is not installed.\r\n",
      "tfx-bsl 1.3.0 requires absl-py<0.13,>=0.9, but you have absl-py 0.14.0 which is incompatible.\r\n",
      "tfx-bsl 1.3.0 requires pyarrow<3,>=1, but you have pyarrow 5.0.0 which is incompatible.\r\n",
      "tfx-bsl 1.3.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<3,>=1.15.2, but you have tensorflow 1.15.0 which is incompatible.\r\n",
      "tensorflow-transform 1.3.0 requires absl-py<0.13,>=0.9, but you have absl-py 0.14.0 which is incompatible.\r\n",
      "tensorflow-transform 1.3.0 requires pyarrow<3,>=1, but you have pyarrow 5.0.0 which is incompatible.\r\n",
      "tensorflow-transform 1.3.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<2.7,>=1.15.2, but you have tensorflow 1.15.0 which is incompatible.\r\n",
      "tensorflow-serving-api 2.6.0 requires tensorflow<3,>=2.6.0, but you have tensorflow 1.15.0 which is incompatible.\r\n",
      "tensorflow-probability 0.13.0rc0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\r\n",
      "tensorflow-io 0.18.0 requires tensorflow<2.6.0,>=2.5.0, but you have tensorflow 1.15.0 which is incompatible.\r\n",
      "tensorflow-cloud 0.1.14 requires tensorboard>=2.3.0, but you have tensorboard 1.15.0 which is incompatible.\r\n",
      "pytorch-lightning 1.4.4 requires tensorboard>=2.2.0, but you have tensorboard 1.15.0 which is incompatible.\u001b[0m\r\n",
      "Successfully installed astor-0.8.1 gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
      "Get:1 http://packages.cloud.google.com/apt gcsfuse-bionic InRelease [5388 B]\r\n",
      "Get:2 http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease [6786 B]\r\n",
      "Get:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\r\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\r\n",
      "Get:5 http://packages.cloud.google.com/apt gcsfuse-bionic/main amd64 Packages [531 B]\r\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\r\n",
      "Get:7 http://packages.cloud.google.com/apt cloud-sdk-bionic/main amd64 Packages [220 kB]\r\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\r\n",
      "Get:9 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [26.8 kB]\r\n",
      "Get:10 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [666 kB]\r\n",
      "Get:11 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1442 kB]\r\n",
      "Get:12 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2430 kB]\r\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [699 kB]\r\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2868 kB]\r\n",
      "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2224 kB]\r\n",
      "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [34.4 kB]\r\n",
      "Fetched 10.9 MB in 3s (3537 kB/s)\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "zlib1g-dev is already the newest version (1:1.2.11.dfsg-0ubuntu2).\r\n",
      "cmake is already the newest version (3.10.2-1ubuntu2.18.04.2).\r\n",
      "The following additional packages will be installed:\r\n",
      "  autotools-dev dh-python file ibverbs-providers libexpat1-dev libfabric1\r\n",
      "  libhwloc-dev libhwloc-plugins libhwloc5 libibverbs-dev libltdl-dev\r\n",
      "  libmagic-mgc libmagic1 libnuma-dev libopenmpi2 libpsm-infinipath1\r\n",
      "  libpython3-dev libpython3.6-dev librdmacm1 libtool ocl-icd-libopencl1\r\n",
      "  openmpi-bin openmpi-common python3.6-dev\r\n",
      "Suggested packages:\r\n",
      "  libhwloc-contrib-plugins libtool-doc openmpi-doc autoconf automaken gfortran\r\n",
      "  | fortran95-compiler gcj-jdk opencl-icd gfortran\r\n",
      "The following NEW packages will be installed:\r\n",
      "  autotools-dev dh-python file ibverbs-providers libexpat1-dev libfabric1\r\n",
      "  libhwloc-dev libhwloc-plugins libhwloc5 libibverbs-dev libltdl-dev\r\n",
      "  libmagic-mgc libmagic1 libnuma-dev libopenmpi-dev libopenmpi2\r\n",
      "  libpsm-infinipath1 libpython3-dev libpython3.6-dev librdmacm1 libtool\r\n",
      "  ocl-icd-libopencl1 openmpi-bin openmpi-common python3-dev python3.6-dev\r\n",
      "0 upgraded, 26 newly installed, 0 to remove and 23 not upgraded.\r\n",
      "Need to get 50.6 MB of archives.\r\n",
      "After this operation, 103 MB of additional disk space will be used.\r\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.4 [184 kB]\r\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.4 [68.6 kB]\r\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 file amd64 1:5.32-2ubuntu0.4 [22.1 kB]\r\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 autotools-dev all 20180224.1 [39.6 kB]\r\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 dh-python all 3.20180325ubuntu2 [89.2 kB]\r\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ibverbs-providers amd64 17.1-1ubuntu0.2 [160 kB]\r\n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libexpat1-dev amd64 2.2.5-3ubuntu0.2 [122 kB]\r\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libpsm-infinipath1 amd64 3.3+20.604758e7-5 [174 kB]\r\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 librdmacm1 amd64 17.1-1ubuntu0.2 [56.1 kB]\r\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libfabric1 amd64 1.5.3-1 [302 kB]\r\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libltdl-dev amd64 2.4.6-2 [162 kB]\r\n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpython3.6-dev amd64 3.6.9-1~18.04ubuntu1.4 [44.9 MB]\r\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpython3-dev amd64 3.6.7-1~18.04 [7328 B]\r\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtool all 2.4.6-2 [194 kB]\r\n",
      "Get:15 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libhwloc5 amd64 1.11.9-1 [105 kB]\r\n",
      "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 ocl-icd-libopencl1 amd64 2.2.11-1ubuntu1 [30.3 kB]\r\n",
      "Get:17 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libhwloc-plugins amd64 1.11.9-1 [12.5 kB]\r\n",
      "Get:18 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenmpi2 amd64 2.1.1-8 [2056 kB]\r\n",
      "Get:19 http://archive.ubuntu.com/ubuntu bionic/universe amd64 openmpi-common all 2.1.1-8 [140 kB]\r\n",
      "Get:20 http://archive.ubuntu.com/ubuntu bionic/universe amd64 openmpi-bin amd64 2.1.1-8 [88.2 kB]\r\n",
      "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3.6-dev amd64 3.6.9-1~18.04ubuntu1.4 [508 kB]\r\n",
      "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-dev amd64 3.6.7-1~18.04 [1288 B]\r\n",
      "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libnuma-dev amd64 2.0.11-2.1ubuntu0.1 [32.3 kB]\r\n",
      "Get:24 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libhwloc-dev amd64 1.11.9-1 [167 kB]\r\n",
      "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libibverbs-dev amd64 17.1-1ubuntu0.2 [103 kB]\r\n",
      "Get:26 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenmpi-dev amd64 2.1.1-8 [925 kB]\r\n",
      "Fetched 50.6 MB in 3s (18.9 MB/s)\r\n",
      "debconf: delaying package configuration, since apt-utils is not installed\r\n",
      "Selecting previously unselected package libmagic-mgc.\r\n",
      "(Reading database ... 109092 files and directories currently installed.)\r\n",
      "Preparing to unpack .../00-libmagic-mgc_1%3a5.32-2ubuntu0.4_amd64.deb ...\r\n",
      "Unpacking libmagic-mgc (1:5.32-2ubuntu0.4) ...\r\n",
      "Selecting previously unselected package libmagic1:amd64.\r\n",
      "Preparing to unpack .../01-libmagic1_1%3a5.32-2ubuntu0.4_amd64.deb ...\r\n",
      "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\r\n",
      "Selecting previously unselected package file.\r\n",
      "Preparing to unpack .../02-file_1%3a5.32-2ubuntu0.4_amd64.deb ...\r\n",
      "Unpacking file (1:5.32-2ubuntu0.4) ...\r\n",
      "Selecting previously unselected package autotools-dev.\r\n",
      "Preparing to unpack .../03-autotools-dev_20180224.1_all.deb ...\r\n",
      "Unpacking autotools-dev (20180224.1) ...\r\n",
      "Selecting previously unselected package dh-python.\r\n",
      "Preparing to unpack .../04-dh-python_3.20180325ubuntu2_all.deb ...\r\n",
      "Unpacking dh-python (3.20180325ubuntu2) ...\r\n",
      "Selecting previously unselected package ibverbs-providers:amd64.\r\n",
      "Preparing to unpack .../05-ibverbs-providers_17.1-1ubuntu0.2_amd64.deb ...\r\n",
      "Unpacking ibverbs-providers:amd64 (17.1-1ubuntu0.2) ...\r\n",
      "Selecting previously unselected package libexpat1-dev:amd64.\r\n",
      "Preparing to unpack .../06-libexpat1-dev_2.2.5-3ubuntu0.2_amd64.deb ...\r\n",
      "Unpacking libexpat1-dev:amd64 (2.2.5-3ubuntu0.2) ...\r\n",
      "Selecting previously unselected package libpsm-infinipath1.\r\n",
      "Preparing to unpack .../07-libpsm-infinipath1_3.3+20.604758e7-5_amd64.deb ...\r\n",
      "Unpacking libpsm-infinipath1 (3.3+20.604758e7-5) ...\r\n",
      "Selecting previously unselected package librdmacm1:amd64.\r\n",
      "Preparing to unpack .../08-librdmacm1_17.1-1ubuntu0.2_amd64.deb ...\r\n",
      "Unpacking librdmacm1:amd64 (17.1-1ubuntu0.2) ...\r\n",
      "Selecting previously unselected package libfabric1.\r\n",
      "Preparing to unpack .../09-libfabric1_1.5.3-1_amd64.deb ...\r\n",
      "Unpacking libfabric1 (1.5.3-1) ...\r\n",
      "Selecting previously unselected package libltdl-dev:amd64.\r\n",
      "Preparing to unpack .../10-libltdl-dev_2.4.6-2_amd64.deb ...\r\n",
      "Unpacking libltdl-dev:amd64 (2.4.6-2) ...\r\n",
      "Selecting previously unselected package libpython3.6-dev:amd64.\r\n",
      "Preparing to unpack .../11-libpython3.6-dev_3.6.9-1~18.04ubuntu1.4_amd64.deb ...\r\n",
      "Unpacking libpython3.6-dev:amd64 (3.6.9-1~18.04ubuntu1.4) ...\r\n",
      "Selecting previously unselected package libpython3-dev:amd64.\r\n",
      "Preparing to unpack .../12-libpython3-dev_3.6.7-1~18.04_amd64.deb ...\r\n",
      "Unpacking libpython3-dev:amd64 (3.6.7-1~18.04) ...\r\n",
      "Selecting previously unselected package libtool.\r\n",
      "Preparing to unpack .../13-libtool_2.4.6-2_all.deb ...\r\n",
      "Unpacking libtool (2.4.6-2) ...\r\n",
      "Selecting previously unselected package libhwloc5:amd64.\r\n",
      "Preparing to unpack .../14-libhwloc5_1.11.9-1_amd64.deb ...\r\n",
      "Unpacking libhwloc5:amd64 (1.11.9-1) ...\r\n",
      "Selecting previously unselected package ocl-icd-libopencl1:amd64.\r\n",
      "Preparing to unpack .../15-ocl-icd-libopencl1_2.2.11-1ubuntu1_amd64.deb ...\r\n",
      "Unpacking ocl-icd-libopencl1:amd64 (2.2.11-1ubuntu1) ...\r\n",
      "Selecting previously unselected package libhwloc-plugins.\r\n",
      "Preparing to unpack .../16-libhwloc-plugins_1.11.9-1_amd64.deb ...\r\n",
      "Unpacking libhwloc-plugins (1.11.9-1) ...\r\n",
      "Selecting previously unselected package libopenmpi2:amd64.\r\n",
      "Preparing to unpack .../17-libopenmpi2_2.1.1-8_amd64.deb ...\r\n",
      "Unpacking libopenmpi2:amd64 (2.1.1-8) ...\r\n",
      "Selecting previously unselected package openmpi-common.\r\n",
      "Preparing to unpack .../18-openmpi-common_2.1.1-8_all.deb ...\r\n",
      "Unpacking openmpi-common (2.1.1-8) ...\r\n",
      "Selecting previously unselected package openmpi-bin.\r\n",
      "Preparing to unpack .../19-openmpi-bin_2.1.1-8_amd64.deb ...\r\n",
      "Unpacking openmpi-bin (2.1.1-8) ...\r\n",
      "Selecting previously unselected package python3.6-dev.\r\n",
      "Preparing to unpack .../20-python3.6-dev_3.6.9-1~18.04ubuntu1.4_amd64.deb ...\r\n",
      "Unpacking python3.6-dev (3.6.9-1~18.04ubuntu1.4) ...\r\n",
      "Selecting previously unselected package python3-dev.\r\n",
      "Preparing to unpack .../21-python3-dev_3.6.7-1~18.04_amd64.deb ...\r\n",
      "Unpacking python3-dev (3.6.7-1~18.04) ...\r\n",
      "Selecting previously unselected package libnuma-dev:amd64.\r\n",
      "Preparing to unpack .../22-libnuma-dev_2.0.11-2.1ubuntu0.1_amd64.deb ...\r\n",
      "Unpacking libnuma-dev:amd64 (2.0.11-2.1ubuntu0.1) ...\r\n",
      "Selecting previously unselected package libhwloc-dev:amd64.\r\n",
      "Preparing to unpack .../23-libhwloc-dev_1.11.9-1_amd64.deb ...\r\n",
      "Unpacking libhwloc-dev:amd64 (1.11.9-1) ...\r\n",
      "Selecting previously unselected package libibverbs-dev:amd64.\r\n",
      "Preparing to unpack .../24-libibverbs-dev_17.1-1ubuntu0.2_amd64.deb ...\r\n",
      "Unpacking libibverbs-dev:amd64 (17.1-1ubuntu0.2) ...\r\n",
      "Selecting previously unselected package libopenmpi-dev.\r\n",
      "Preparing to unpack .../25-libopenmpi-dev_2.1.1-8_amd64.deb ...\r\n",
      "Unpacking libopenmpi-dev (2.1.1-8) ...\r\n",
      "Setting up libltdl-dev:amd64 (2.4.6-2) ...\r\n",
      "Setting up librdmacm1:amd64 (17.1-1ubuntu0.2) ...\r\n",
      "Setting up libhwloc5:amd64 (1.11.9-1) ...\r\n",
      "Setting up libmagic-mgc (1:5.32-2ubuntu0.4) ...\r\n",
      "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\r\n",
      "Setting up libpsm-infinipath1 (3.3+20.604758e7-5) ...\r\n",
      "update-alternatives: using /usr/lib/libpsm1/libpsm_infinipath.so.1.16 to provide /usr/lib/x86_64-linux-gnu/libpsm_infinipath.so.1 (libpsm_infinipath.so.1) in auto mode\r\n",
      "Setting up openmpi-common (2.1.1-8) ...\r\n",
      "Setting up autotools-dev (20180224.1) ...\r\n",
      "Setting up ibverbs-providers:amd64 (17.1-1ubuntu0.2) ...\r\n",
      "Setting up libexpat1-dev:amd64 (2.2.5-3ubuntu0.2) ...\r\n",
      "Setting up libnuma-dev:amd64 (2.0.11-2.1ubuntu0.1) ...\r\n",
      "Setting up ocl-icd-libopencl1:amd64 (2.2.11-1ubuntu1) ...\r\n",
      "Setting up dh-python (3.20180325ubuntu2) ...\r\n",
      "Setting up libibverbs-dev:amd64 (17.1-1ubuntu0.2) ...\r\n",
      "Setting up libfabric1 (1.5.3-1) ...\r\n",
      "Setting up libhwloc-dev:amd64 (1.11.9-1) ...\r\n",
      "Setting up file (1:5.32-2ubuntu0.4) ...\r\n",
      "Setting up libpython3.6-dev:amd64 (3.6.9-1~18.04ubuntu1.4) ...\r\n",
      "Setting up libhwloc-plugins (1.11.9-1) ...\r\n",
      "Setting up libopenmpi2:amd64 (2.1.1-8) ...\r\n",
      "Setting up python3.6-dev (3.6.9-1~18.04ubuntu1.4) ...\r\n",
      "Setting up libpython3-dev:amd64 (3.6.7-1~18.04) ...\r\n",
      "Setting up libtool (2.4.6-2) ...\r\n",
      "Setting up libopenmpi-dev (2.1.1-8) ...\r\n",
      "update-alternatives: using /usr/lib/x86_64-linux-gnu/openmpi/include to provide /usr/include/mpi (mpi) in auto mode\r\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/mpicc.1.gz because associated file /usr/share/man/man1/mpicc.openmpi.1.gz (of link group mpi) doesn't exist\r\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/mpic++.1.gz because associated file /usr/share/man/man1/mpic++.openmpi.1.gz (of link group mpi) doesn't exist\r\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/mpicxx.1.gz because associated file /usr/share/man/man1/mpicxx.openmpi.1.gz (of link group mpi) doesn't exist\r\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/mpiCC.1.gz because associated file /usr/share/man/man1/mpiCC.openmpi.1.gz (of link group mpi) doesn't exist\r\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/mpif77.1.gz because associated file /usr/share/man/man1/mpif77.openmpi.1.gz (of link group mpi) doesn't exist\r\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/mpif90.1.gz because associated file /usr/share/man/man1/mpif90.openmpi.1.gz (of link group mpi) doesn't exist\r\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/mpifort.1.gz because associated file /usr/share/man/man1/mpifort.openmpi.1.gz (of link group mpi) doesn't exist\r\n",
      "Setting up python3-dev (3.6.7-1~18.04) ...\r\n",
      "Setting up openmpi-bin (2.1.1-8) ...\r\n",
      "update-alternatives: using /usr/bin/mpirun.openmpi to provide /usr/bin/mpirun (mpirun) in auto mode\r\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/mpirun.1.gz because associated file /usr/share/man/man1/mpirun.openmpi.1.gz (of link group mpirun) doesn't exist\r\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/mpiexec.1.gz because associated file /usr/share/man/man1/mpiexec.openmpi.1.gz (of link group mpirun) doesn't exist\r\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1.4) ...\r\n",
      "Collecting stable-baselines[mpi]==2.9.0\r\n",
      "  Downloading stable_baselines-2.9.0-py3-none-any.whl (232 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 232 kB 5.1 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: cloudpickle>=0.5.5 in /opt/conda/lib/python3.7/site-packages (from stable-baselines[mpi]==2.9.0) (2.0.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from stable-baselines[mpi]==2.9.0) (1.19.5)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from stable-baselines[mpi]==2.9.0) (1.0.1)\r\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from stable-baselines[mpi]==2.9.0) (4.5.4.58)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from stable-baselines[mpi]==2.9.0) (1.3.3)\r\n",
      "Requirement already satisfied: gym[atari,classic_control]>=0.10.9 in /opt/conda/lib/python3.7/site-packages (from stable-baselines[mpi]==2.9.0) (0.21.0)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from stable-baselines[mpi]==2.9.0) (1.7.1)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from stable-baselines[mpi]==2.9.0) (3.4.3)\r\n",
      "Collecting mpi4py\r\n",
      "  Downloading mpi4py-3.1.3.tar.gz (2.5 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 2.5 MB 59.6 MB/s \r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata>=4.8.1 in /opt/conda/lib/python3.7/site-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines[mpi]==2.9.0) (4.8.1)\r\n",
      "Collecting pyglet>=1.4.0\r\n",
      "  Downloading pyglet-1.5.21-py3-none-any.whl (1.1 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 47.6 MB/s \r\n",
      "\u001b[?25hCollecting ale-py~=0.7.1\r\n",
      "  Downloading ale_py-0.7.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 28.5 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.7/site-packages (from ale-py~=0.7.1->gym[atari,classic_control]>=0.10.9->stable-baselines[mpi]==2.9.0) (5.2.2)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.8.1->gym[atari,classic_control]>=0.10.9->stable-baselines[mpi]==2.9.0) (3.5.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.8.1->gym[atari,classic_control]>=0.10.9->stable-baselines[mpi]==2.9.0) (3.10.0.2)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines[mpi]==2.9.0) (2.4.7)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines[mpi]==2.9.0) (1.3.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines[mpi]==2.9.0) (2.8.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines[mpi]==2.9.0) (0.10.0)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines[mpi]==2.9.0) (8.2.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->stable-baselines[mpi]==2.9.0) (1.16.0)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->stable-baselines[mpi]==2.9.0) (2021.1)\r\n",
      "Building wheels for collected packages: mpi4py\r\n",
      "  Building wheel for mpi4py (PEP 517) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for mpi4py: filename=mpi4py-3.1.3-cp37-cp37m-linux_x86_64.whl size=2211822 sha256=1b5973c67c8930430f405c5c5199e7190f1728812163957b09c3327deee24dfa\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/7a/07/14/6a0c63fa2c6e473c6edc40985b7d89f05c61ff25ee7f0ad9ac\r\n",
      "Successfully built mpi4py\r\n",
      "Installing collected packages: pyglet, ale-py, stable-baselines, mpi4py\r\n",
      "Successfully installed ale-py-0.7.3 mpi4py-3.1.3 pyglet-1.5.21 stable-baselines-2.9.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install 'tensorflow==1.15.0'\n",
    "!apt-get update\n",
    "!apt-get install -y cmake libopenmpi-dev python3-dev zlib1g-dev\n",
    "!pip install \"stable-baselines[mpi]==2.9.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab78e22f",
   "metadata": {
    "papermill": {
     "duration": 0.253668,
     "end_time": "2021-11-26T02:19:41.616843",
     "exception": false,
     "start_time": "2021-11-26T02:19:41.363175",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span class=\"title-section w3-xxlarge\" id=\"outline\">Libraries 📚</span>\n",
    "<hr>\n",
    "\n",
    "#### Code starts here ⬇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26983631",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-26T02:19:42.138712Z",
     "iopub.status.busy": "2021-11-26T02:19:42.137804Z",
     "iopub.status.idle": "2021-11-26T02:19:47.637093Z",
     "shell.execute_reply": "2021-11-26T02:19:47.636267Z",
     "shell.execute_reply.started": "2021-11-08T05:48:30.905018Z"
    },
    "papermill": {
     "duration": 5.76658,
     "end_time": "2021-11-26T02:19:47.637239",
     "exception": false,
     "start_time": "2021-11-26T02:19:41.870659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ale_py/roms/utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
      "  for external in metadata.entry_points().get(self.group, []):\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import datetime\n",
    "import traceback\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import gresearch_crypto\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines import PPO2\n",
    "from stable_baselines.common.policies import MlpPolicy, MlpLnLstmPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9e8b399",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-26T02:19:48.150701Z",
     "iopub.status.busy": "2021-11-26T02:19:48.149930Z",
     "iopub.status.idle": "2021-11-26T02:19:48.153668Z",
     "shell.execute_reply": "2021-11-26T02:19:48.154221Z",
     "shell.execute_reply.started": "2021-11-08T05:48:35.772802Z"
    },
    "papermill": {
     "duration": 0.262247,
     "end_time": "2021-11-26T02:19:48.154399",
     "exception": false,
     "start_time": "2021-11-26T02:19:47.892152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483467bc",
   "metadata": {
    "papermill": {
     "duration": 0.253333,
     "end_time": "2021-11-26T02:19:48.661967",
     "exception": false,
     "start_time": "2021-11-26T02:19:48.408634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span class=\"title-section w3-xxlarge\" id=\"loading\">Data Loading 🗃️</span>\n",
    "<hr>\n",
    "\n",
    "The data organisation has already been done and saved to Kaggle datasets. Here we choose which years to load. We can use either 2017, 2018, 2019, 2020, 2021, Original, Supplement by changing the `INC2021`, `INC2020`, `INC2019`, `INC2018`, `INC2017`, `INCCOMP`, `INCSUPP` variables in the preceeding code section. These datasets are discussed [here][1].\n",
    "\n",
    "[1]: https://www.kaggle.com/c/g-research-crypto-forecasting/discussion/285726\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7933c245",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-11-26T02:19:49.207432Z",
     "iopub.status.busy": "2021-11-26T02:19:49.200883Z",
     "iopub.status.idle": "2021-11-26T02:20:14.870916Z",
     "shell.execute_reply": "2021-11-26T02:20:14.869911Z",
     "shell.execute_reply.started": "2021-11-08T05:48:35.779205Z"
    },
    "papermill": {
     "duration": 25.954446,
     "end_time": "2021-11-26T02:20:14.871088",
     "exception": false,
     "start_time": "2021-11-26T02:19:48.916642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datatable as dt\n",
    "extra_data_files = {0: '../input/cryptocurrency-extra-data-binance-coin', 2: '../input/cryptocurrency-extra-data-bitcoin-cash', 1: '../input/cryptocurrency-extra-data-bitcoin', 3: '../input/cryptocurrency-extra-data-cardano', 4: '../input/cryptocurrency-extra-data-dogecoin', 5: '../input/cryptocurrency-extra-data-eos-io', 6: '../input/cryptocurrency-extra-data-ethereum', 7: '../input/cryptocurrency-extra-data-ethereum-classic', 8: '../input/cryptocurrency-extra-data-iota', 9: '../input/cryptocurrency-extra-data-litecoin', 11: '../input/cryptocurrency-extra-data-monero', 10: '../input/cryptocurrency-extra-data-maker', 12: '../input/cryptocurrency-extra-data-stellar', 13: '../input/cryptocurrency-extra-data-tron'}\n",
    "\n",
    "# Uncomment to load the original csv [slower]\n",
    "# orig_df_train = pd.read_csv(data_path + 'train.csv') \n",
    "# supp_df_train = pd.read_csv(data_path + 'supplemental_train.csv')\n",
    "# df_asset_details = pd.read_csv(data_path  + 'asset_details.csv').sort_values(\"Asset_ID\")\n",
    "\n",
    "orig_df_train = dt.fread('../input/cryptocurrency-extra-data-binance-coin/orig_train.jay').to_pandas()\n",
    "df_asset_details = dt.fread('../input/cryptocurrency-extra-data-binance-coin/orig_asset_details.jay').to_pandas()\n",
    "supp_df_train = dt.fread('../input/cryptocurrency-extra-data-binance-coin/orig_supplemental_train.jay').to_pandas()\n",
    "assets_details = dt.fread('../input/cryptocurrency-extra-data-binance-coin/orig_asset_details.jay').to_pandas()\n",
    "asset_weight_dict = {assets_details['Asset_ID'].tolist()[idx]: assets_details['Weight'].tolist()[idx] for idx in range(len(assets_details))}\n",
    "asset_name_dict = {assets_details['Asset_ID'].tolist()[idx]: assets_details['Asset_Name'].tolist()[idx] for idx in range(len(assets_details))}\n",
    "\n",
    "def load_training_data_for_asset(asset_id, load_jay = True):\n",
    "    dfs = []\n",
    "    if INCCOMP: dfs.append(orig_df_train[orig_df_train[\"Asset_ID\"] == asset_id].copy())\n",
    "    if INCSUPP: dfs.append(supp_df_train[supp_df_train[\"Asset_ID\"] == asset_id].copy())\n",
    "    \n",
    "    if load_jay:\n",
    "        if INC2017 and os.path.exists(extra_data_files[asset_id] + '/full_data__' + str(asset_id) + '__' + str(2017) + '.csv'): dfs.append(dt.fread(extra_data_files[asset_id] + '/full_data__' + str(asset_id) + '__' + str(2017) + '.jay').to_pandas())\n",
    "        if INC2018 and os.path.exists(extra_data_files[asset_id] + '/full_data__' + str(asset_id) + '__' + str(2018) + '.csv'): dfs.append(dt.fread(extra_data_files[asset_id] + '/full_data__' + str(asset_id) + '__' + str(2018) + '.jay').to_pandas())\n",
    "        if INC2019 and os.path.exists(extra_data_files[asset_id] + '/full_data__' + str(asset_id) + '__' + str(2019) + '.csv'): dfs.append(dt.fread(extra_data_files[asset_id] + '/full_data__' + str(asset_id) + '__' + str(2019) + '.jay').to_pandas())\n",
    "        if INC2020 and os.path.exists(extra_data_files[asset_id] + '/full_data__' + str(asset_id) + '__' + str(2020) + '.csv'): dfs.append(dt.fread(extra_data_files[asset_id] + '/full_data__' + str(asset_id) + '__' + str(2020) + '.jay').to_pandas())\n",
    "        if INC2021 and os.path.exists(extra_data_files[asset_id] + '/full_data__' + str(asset_id) + '__' + str(2021) + '.csv'): dfs.append(dt.fread(extra_data_files[asset_id] + '/full_data__' + str(asset_id) + '__' + str(2021) + '.jay').to_pandas())\n",
    "    else: \n",
    "        if INC2017 and os.path.exists(extra_data_files[asset_id] + '/full_data__' + str(asset_id) + '__' + str(2017) + '.csv'): dfs.append(pd.read_csv(extra_data_files[asset_id] + '/full_data__' + str(asset_id) + '__' + str(2017) + '.csv'))\n",
    "        if INC2018 and os.path.exists(extra_data_files[asset_id] + '/full_data__' + str(asset_id) + '__' + str(2018) + '.csv'): dfs.append(pd.read_csv(extra_data_files[asset_id] + '/full_data__' + str(asset_id) + '__' + str(2018) + '.csv'))\n",
    "        if INC2019 and os.path.exists(extra_data_files[asset_id] + '/full_data__' + str(asset_id) + '__' + str(2019) + '.csv'): dfs.append(pd.read_csv(extra_data_files[asset_id] + '/full_data__' + str(asset_id) + '__' + str(2019) + '.csv'))\n",
    "        if INC2020 and os.path.exists(extra_data_files[asset_id] + '/full_data__' + str(asset_id) + '__' + str(2020) + '.csv'): dfs.append(pd.read_csv(extra_data_files[asset_id] + '/full_data__' + str(asset_id) + '__' + str(2020) + '.csv'))\n",
    "        if INC2021 and os.path.exists(extra_data_files[asset_id] + '/full_data__' + str(asset_id) + '__' + str(2021) + '.csv'): dfs.append(pd.read_csv(extra_data_files[asset_id] + '/full_data__' + str(asset_id) + '__' + str(2021) + '.csv'))\n",
    "    df = pd.concat(dfs, axis = 0) if len(dfs) > 1 else dfs[0]\n",
    "    df['date'] = pd.to_datetime(df['timestamp'], unit = 's')\n",
    "    if LOAD_STRICT: df = df.loc[df['date'] < \"2021-06-13 00:00:00\"]    \n",
    "    df = df.sort_values('date')\n",
    "    return df\n",
    "\n",
    "def load_data_for_all_assets():\n",
    "    dfs = []\n",
    "    for asset_id in list(extra_data_files.keys()): dfs.append(load_training_data_for_asset(asset_id))\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eef6e17b",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-11-26T02:20:15.423373Z",
     "iopub.status.busy": "2021-11-26T02:20:15.422671Z",
     "iopub.status.idle": "2021-11-26T02:20:27.396994Z",
     "shell.execute_reply": "2021-11-26T02:20:27.396398Z",
     "shell.execute_reply.started": "2021-11-08T05:48:35.779205Z"
    },
    "papermill": {
     "duration": 12.26603,
     "end_time": "2021-11-26T02:20:27.397157",
     "exception": false,
     "start_time": "2021-11-26T02:20:15.131127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded all data!\n"
     ]
    }
   ],
   "source": [
    "# LOAD STRICT? YES=1 NO=0 | see: https://www.kaggle.com/julian3833/proposal-for-a-meaningful-lb-strict-lgbm\n",
    "LOAD_STRICT = True\n",
    "\n",
    "# WHICH YEARS TO INCLUDE? YES=1 NO=0\n",
    "INC2021 = 0\n",
    "INC2020 = 0\n",
    "INC2019 = 0\n",
    "INC2018 = 0\n",
    "INC2017 = 0\n",
    "INCCOMP = 1\n",
    "INCSUPP = 0\n",
    "\n",
    "train = load_data_for_all_assets()\n",
    "test = pd.read_csv('../input/g-research-crypto-forecasting/example_test.csv')\n",
    "sample_prediction_df = pd.read_csv('../input/g-research-crypto-forecasting/example_sample_submission.csv')\n",
    "print (\"Loaded all data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858fca1a",
   "metadata": {
    "papermill": {
     "duration": 0.254744,
     "end_time": "2021-11-26T02:20:27.908309",
     "exception": false,
     "start_time": "2021-11-26T02:20:27.653565",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span class=\"title-section w3-xxlarge\" id=\"features\">Feature Engineering 🔬</span>\n",
    "<hr>\n",
    "\n",
    "This notebook uses upper_shadow, lower_shadow, high_div_low, open_sub_close, seasonality/datetime features first shown in this notebook [here][1] and successfully used by julian3833 [here][2].\n",
    "\n",
    "Additionally we can decide to use external data by changing the variables `INC2021`, `INC2020`, `INC2019`, `INC2018`, `INC2017`, `INCCOMP`, `INCSUPP` in the preceeding code section. These variables respectively indicate whether to load last year 2021 data and/or year 2020, 2019, 2018, 2017, the original, supplemented data. These datasets are discussed [here][3]\n",
    "\n",
    "Consider experimenting with different feature engineering and/or external data. The code to extract features out of the dataset is taken from julian3833' notebook [here][2]. Thank you julian3833, this is great work.\n",
    "\n",
    "[1]: https://www.kaggle.com/cstein06/tutorial-to-the-g-research-crypto-competition\n",
    "[2]: https://www.kaggle.com/julian3833\n",
    "[3]: TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e89b08c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-26T02:20:28.426633Z",
     "iopub.status.busy": "2021-11-26T02:20:28.425923Z",
     "iopub.status.idle": "2021-11-26T02:20:28.432568Z",
     "shell.execute_reply": "2021-11-26T02:20:28.433149Z",
     "shell.execute_reply.started": "2021-11-08T05:49:19.713568Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.266106,
     "end_time": "2021-11-26T02:20:28.433340",
     "exception": false,
     "start_time": "2021-11-26T02:20:28.167234",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Two features from the competition tutorial\n",
    "def upper_shadow(df): return df['High'] - np.maximum(df['Close'], df['Open'])\n",
    "def lower_shadow(df): return np.minimum(df['Close'], df['Open']) - df['Low']\n",
    "\n",
    "# A utility function to build features from the original df\n",
    "def get_features(df):\n",
    "    df_feat = df[['Count', 'Open', 'High', 'Low', 'Close', 'Volume', 'VWAP']].copy()\n",
    "    df_feat['upper_Shadow'] = upper_shadow(df_feat)\n",
    "    df_feat['lower_Shadow'] = lower_shadow(df_feat)\n",
    "    df_feat[\"high_div_low\"] = df_feat[\"High\"] / df_feat[\"Low\"]\n",
    "    df_feat[\"open_sub_close\"] = df_feat[\"Open\"] - df_feat[\"Close\"]\n",
    "    return df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10c5fc31",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-11-26T02:20:28.950702Z",
     "iopub.status.busy": "2021-11-26T02:20:28.949833Z",
     "iopub.status.idle": "2021-11-26T02:20:28.965002Z",
     "shell.execute_reply": "2021-11-26T02:20:28.965587Z",
     "shell.execute_reply.started": "2021-11-08T05:49:19.721618Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.277331,
     "end_time": "2021-11-26T02:20:28.965770",
     "exception": false,
     "start_time": "2021-11-26T02:20:28.688439",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df,do_categoricals=False):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.\n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            if do_categoricals==True:\n",
    "                df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37918bf3",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-11-26T02:20:29.493566Z",
     "iopub.status.busy": "2021-11-26T02:20:29.491800Z",
     "iopub.status.idle": "2021-11-26T02:20:38.213703Z",
     "shell.execute_reply": "2021-11-26T02:20:38.212980Z",
     "shell.execute_reply.started": "2021-11-08T05:49:19.736946Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 8.987899,
     "end_time": "2021-11-26T02:20:38.213861",
     "exception": false,
     "start_time": "2021-11-26T02:20:29.225962",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 1525.84 MB\n",
      "Memory usage after optimization is: 699.34 MB\n",
      "Decreased by 54.2%\n"
     ]
    }
   ],
   "source": [
    "train = train.sort_values('timestamp')\n",
    "train.drop(columns = 'timestamp', inplace = True)\n",
    "train.drop(columns = 'date', inplace = True)\n",
    "target = train['Target'].copy()\n",
    "train.drop(columns = 'Target', inplace = True)\n",
    "train = reduce_mem_usage(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61905c4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-26T02:20:38.737191Z",
     "iopub.status.busy": "2021-11-26T02:20:38.735920Z",
     "iopub.status.idle": "2021-11-26T02:20:44.155774Z",
     "shell.execute_reply": "2021-11-26T02:20:44.155133Z",
     "shell.execute_reply.started": "2021-11-08T05:49:28.949331Z"
    },
    "papermill": {
     "duration": 5.681928,
     "end_time": "2021-11-26T02:20:44.155912",
     "exception": false,
     "start_time": "2021-11-26T02:20:38.473984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 699.34 MB\n",
      "Memory usage after optimization is: 699.34 MB\n",
      "Decreased by 0.0%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Asset_ID</th>\n",
       "      <th>Count</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>VWAP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.531250</td>\n",
       "      <td>8.531250</td>\n",
       "      <td>8.53125</td>\n",
       "      <td>8.53125</td>\n",
       "      <td>78.379997</td>\n",
       "      <td>8.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7.660156</td>\n",
       "      <td>7.660156</td>\n",
       "      <td>7.65625</td>\n",
       "      <td>7.65625</td>\n",
       "      <td>6626.713379</td>\n",
       "      <td>7.657713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>7.0</td>\n",
       "      <td>329.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>329.00000</td>\n",
       "      <td>329.50000</td>\n",
       "      <td>6.635710</td>\n",
       "      <td>329.454118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>173.0</td>\n",
       "      <td>738.500000</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>732.50000</td>\n",
       "      <td>738.50000</td>\n",
       "      <td>335.987854</td>\n",
       "      <td>738.839291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.921875</td>\n",
       "      <td>25.921875</td>\n",
       "      <td>25.87500</td>\n",
       "      <td>25.87500</td>\n",
       "      <td>121.087311</td>\n",
       "      <td>25.891363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Asset_ID  Count        Open        High        Low      Close       Volume  \\\n",
       "1         0    5.0    8.531250    8.531250    8.53125    8.53125    78.379997   \n",
       "3         5   32.0    7.660156    7.660156    7.65625    7.65625  6626.713379   \n",
       "7        11    7.0  329.000000  330.000000  329.00000  329.50000     6.635710   \n",
       "5         6  173.0  738.500000  746.000000  732.50000  738.50000   335.987854   \n",
       "4         7    5.0   25.921875   25.921875   25.87500   25.87500   121.087311   \n",
       "\n",
       "         VWAP  \n",
       "1    8.530000  \n",
       "3    7.657713  \n",
       "7  329.454118  \n",
       "5  738.839291  \n",
       "4   25.891363  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trian = get_features(train)\n",
    "train = reduce_mem_usage(train)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1285b43e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-26T02:20:44.684624Z",
     "iopub.status.busy": "2021-11-26T02:20:44.683944Z",
     "iopub.status.idle": "2021-11-26T02:20:44.687805Z",
     "shell.execute_reply": "2021-11-26T02:20:44.688277Z",
     "shell.execute_reply.started": "2021-11-08T05:49:35.042175Z"
    },
    "papermill": {
     "duration": 0.265165,
     "end_time": "2021-11-26T02:20:44.688451",
     "exception": false,
     "start_time": "2021-11-26T02:20:44.423286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now()\n",
    "MODEL_ID = f\"g_research_ppo_{timestamp.strftime('%s')}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a65aec8",
   "metadata": {
    "papermill": {
     "duration": 0.261916,
     "end_time": "2021-11-26T02:20:45.208900",
     "exception": false,
     "start_time": "2021-11-26T02:20:44.946984",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span class=\"title-section w3-xxlarge\" id=\"config\">Defining the GYM Environment 🎚️</span>\n",
    "<hr >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38f3dfdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-26T02:20:45.728660Z",
     "iopub.status.busy": "2021-11-26T02:20:45.727615Z",
     "iopub.status.idle": "2021-11-26T02:20:47.661412Z",
     "shell.execute_reply": "2021-11-26T02:20:47.660864Z",
     "shell.execute_reply.started": "2021-11-08T05:49:35.049037Z"
    },
    "papermill": {
     "duration": 2.193096,
     "end_time": "2021-11-26T02:20:47.661590",
     "exception": false,
     "start_time": "2021-11-26T02:20:45.468494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gym/spaces/box.py:74: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  \"Box bound precision lowered by casting to {}\".format(self.dtype)\n"
     ]
    }
   ],
   "source": [
    "class GResearchEnv(gym.Env):\n",
    "\n",
    "    def __init__(self, df, target, window_size = 5):\n",
    "        super(GResearchEnv, self).__init__()\n",
    "        self.idx = 0\n",
    "        self.df = df\n",
    "        self.n_samples = df.shape[0]\n",
    "        self.window_size = window_size\n",
    "        self.target = target.values\n",
    "        self.features = [col for col in list(self.df.columns)]\n",
    "        self.states = df[[col for col in list(self.df.columns)]].values\n",
    "        # Possible actions = target estimate\n",
    "        self.action_space = spaces.Box( np.array([-1.0]), np.array([+1.0])) \n",
    "        # Prices contains the technical feature values for the last five prices\n",
    "        self.observation_space = spaces.Box(low=-8.215050, high=5.872849e+01, shape=(df[self.features].shape[1], self.window_size))\n",
    "\n",
    "    def _next_observation(self):         \n",
    "        return np.array([self.df[self.idx: self.idx + self.window_size][feature].values for feature in self.features])\n",
    "\n",
    "    def step(self, action):\n",
    "        obs = self._next_observation()\n",
    "        reward = -1.0 * (action - self.target[self.idx]) # Rewarding the agent inversely proportional to it's error\n",
    "        self.idx += 1\n",
    "        if self.idx >= self.n_samples - self.window_size:\n",
    "            done = True\n",
    "            self.idx = 0\n",
    "        else: done = False\n",
    "        return obs, reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.idx = 0\n",
    "        return self._next_observation()\n",
    "\n",
    "    def render(self):\n",
    "        print(f'Step: {self.idx}')\n",
    "\n",
    "        \n",
    "class GResearchPredictEnv(gym.Env):\n",
    "\n",
    "    def __init__(self, df, target, window_size = 5):\n",
    "        super(GResearchPredictEnv, self).__init__()\n",
    "        self.idx = 0\n",
    "        self.df = df\n",
    "        self.n_samples = df.shape[0]\n",
    "        self.window_size = window_size\n",
    "        self.target = target.values\n",
    "        self.features = [col for col in list(self.df.columns)]\n",
    "        self.states = df[[col for col in list(self.df.columns)]].values\n",
    "        # Possible actions = target estimate\n",
    "        self.action_space = spaces.Box( np.array([-1.0]), np.array([+1.0])) \n",
    "        # Prices contains the technical feature values for the last five prices\n",
    "        self.observation_space = spaces.Box(low=-8.215050, high=5.872849e+01, shape=(df[self.features].shape[1], self.window_size))\n",
    "\n",
    "    def _next_observation(self):         \n",
    "        return np.array([self.df[self.idx: self.idx + self.window_size][feature].values for feature in self.features])\n",
    "\n",
    "    def step(self, action):\n",
    "        obs = self._next_observation()\n",
    "        reward = -1.0 * (action - self.target[self.idx]) # Rewarding the agent inversely proportional to it's error\n",
    "        self.idx += 1\n",
    "        if self.idx >= self.n_samples - self.window_size:\n",
    "            done = True\n",
    "            self.idx = 0\n",
    "        else: done = False\n",
    "        return obs, reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.idx = 0\n",
    "        return self._next_observation()\n",
    "\n",
    "    def render(self):\n",
    "        print(f'Step: {self.idx}')\n",
    "        \n",
    "features, window_size = [col for col in list(train.columns)], WINDOW_SIZE\n",
    "env = DummyVecEnv([lambda: GResearchEnv(train, target, window_size = WINDOW_SIZE)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ece8b1",
   "metadata": {
    "papermill": {
     "duration": 0.259938,
     "end_time": "2021-11-26T02:20:48.180914",
     "exception": false,
     "start_time": "2021-11-26T02:20:47.920976",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span class=\"title-section w3-xxlarge\" id=\"training\">Reinforcement Learning 🏋️</span>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6106bc88",
   "metadata": {
    "papermill": {
     "duration": 0.256065,
     "end_time": "2021-11-26T02:20:48.715382",
     "exception": false,
     "start_time": "2021-11-26T02:20:48.459317",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Network architecture <a name=\"architecture\"></a>\n",
    "\n",
    "We are going to train a neural network, which is structured in the following way:\n",
    "\n",
    "\n",
    "                                -------> Actor ---> Logits (𝜋)\n",
    "                              /\n",
    "    State (𝑠) ---> Encoder --- --------> Critic-1 ---> Value-1 (𝑉-1)\n",
    "                              \\\n",
    "                                -------> Critic-2 ---> Value-2 (𝑉-2)\n",
    "\n",
    "\n",
    "Each critic head predicts state-value $V_\\theta(s)$ (estimate of discounted return from this point onwards), where $\\theta$ stands for neural net parameters. Actor updates policy parameters for $\\pi_\\theta$, in the direction suggested by Critics.\n",
    "\n",
    "I won't go into details here, for more reading visit this amazing notebook: https://www.kaggle.com/alexandersamarin/training-resnet-agent-from-scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a49aee1",
   "metadata": {
    "papermill": {
     "duration": 0.280222,
     "end_time": "2021-11-26T02:20:49.255480",
     "exception": false,
     "start_time": "2021-11-26T02:20:48.975258",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## PPO algorithm explained <a name=\"ppo\"></a>\n",
    "\n",
    "Firstly, we will define policy gradient loss:\n",
    "\n",
    "$$\\mathcal{L}^{\\text{PG}}(\\theta) = \\mathbb{E}[\\log \\pi_\\theta(a|s) \\hat{A}_\\theta(s,a) ],$$\n",
    "\n",
    "where first term $\\log \\pi_\\theta(a|s)$ are log-probabilities from the output of policy network (actor head), and the second one is an estimate of `advantage function`, the relative value of selected action $a$. The value of $\\hat{A}_\\theta(s,a)$ is equal to `return` (or `discounted reward`) minus `baseline estimate`. Return at given time $t$ is calculated as follows:\n",
    "\n",
    "$$ V_{\\text{target}}(t) = R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots = \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1},$$\n",
    "\n",
    "where $R^i_t$ is a reward at timestep $t$. Baseline estimate is the output of value network $V_\\theta(s)$. Therefore,\n",
    "\n",
    "$$ \\hat{A}_\\theta(t) = V_{\\text{target}}(t) - V_\\theta(s_t). $$\n",
    "\n",
    "There also exists a generalized version of advantage estimation, that we are going to use:\n",
    "\n",
    "$$\\hat{A}_\\theta(t) = \\delta_t + (\\gamma \\lambda) \\delta_{t+1} + \\dots = \\sum_{k=0}^\\infty (\\gamma \\lambda)^k \\delta_{t+k+1},$$\n",
    "$$ \\text{where } \\delta_t = R_t + \\gamma V_\\theta(s_{t+1}) - V_\\theta(s_t),$$\n",
    "\n",
    "which is reduced to previous equation when $\\lambda = 1$.\n",
    "\n",
    "Now, when $\\hat{A}_\\theta$ is positive, meaning that the action agent took resulted in a better than average return, we will increase probabilities of selecting it again in the future. On the other hand, if an advantage was negative, we will reduce the likelihood of selected actions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14edbb12",
   "metadata": {
    "papermill": {
     "duration": 0.266924,
     "end_time": "2021-11-26T02:20:49.785849",
     "exception": false,
     "start_time": "2021-11-26T02:20:49.518925",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "However, as PPO-paper quotes:\n",
    "\n",
    "`While it is appealing to perform multiple steps of optimization on this loss using the same trajectory, doing so is not well-justified, and empirically it often leads to destructively large policy updates.`\n",
    "\n",
    "In other words, we have to impose the constraint which won't allow our new policy to move too far away from an old one. Let’s denote the probability ratio between old and new policies as\n",
    "\n",
    "$$r(\\theta) = \\frac{\\pi_{\\theta}(a|s)}{\\pi_{\\theta_{\\text{old}}}(a|s)}. $$\n",
    "\n",
    "Then, take a look at our new `surrogate` objective function:\n",
    "\n",
    "$$\\mathcal{L}^{\\text{CPI}}(\\theta) = \\mathbb{E}[r(\\theta) \\hat{A}_\\theta(s,a)].$$\n",
    "\n",
    "It can be derived that maximimizing $\\mathcal{L}^{\\text{CPI}}(\\theta)$ is identical to vanilla policy gradient method, but I'll bravely skip the proof. Now, we would like to insert the aforementioned constraint into this loss function. The main objective which PPO-parer proposes is the following.\n",
    "\n",
    "$$J^{\\text{CLIP}}(\\theta) = \\mathbb{E}[\\min (r(\\theta) \\hat{A}_{\\theta_{\\text{old}}}(s,a), \\text{clip}(r(\\theta), 1-\\epsilon, 1+\\epsilon)\\hat{A}_{\\theta_{\\text{old}}}(s,a)],$$\n",
    "\n",
    "where $\\epsilon$ is a `clip ratio` hyperparameter. The first term inside $min$ function, $r(\\theta) \\hat{A}_{\\theta_{\\text{old}}}(s,a)$ is a normal policy gradient objective. And the second one is its clipped version, which doesn't allow us to destroy our current policy based on a single estimate, because the value of $\\hat{A}_{\\theta_{\\text{old}}}(s,a)$ is noisy (as it is based on an output of our network).\n",
    "\n",
    "When applying PPO on the network architecture with shared parameters for both policy and value functions, in addition to the clipped reward, the objective function is augmented with an error term on the value estimation and an entropy term to encourage sufficient exploration. Final loss then becomes:\n",
    "\n",
    "$$\\mathcal{L}(\\theta) = \\mathbb{E}[-J(\\theta) + c  (V_\\theta(s) - V_{\\text{target}})^2 - c_{\\text{ent}}  H(s, \\pi_{\\theta}(\\cdot))], $$\n",
    "\n",
    "where $c$ and $c_{\\text{ent}}$ are both hyperparameter constants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b1da66",
   "metadata": {
    "papermill": {
     "duration": 0.26049,
     "end_time": "2021-11-26T02:20:50.307497",
     "exception": false,
     "start_time": "2021-11-26T02:20:50.047007",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## OpenAI's stable baselines\n",
    "To use this on the competition, we should implement it from scratch since we are not allowed to use internet on the final submissions. \n",
    "Currently, to get things up and running: We are simply going to use OpenAI's stable-baselines. \n",
    "As this is a work in progress: The next versions of this notebok will contain an ecapsulated implementation of the PPO agent. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68df2af0",
   "metadata": {
    "papermill": {
     "duration": 0.257534,
     "end_time": "2021-11-26T02:20:50.821052",
     "exception": false,
     "start_time": "2021-11-26T02:20:50.563518",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc459b57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-26T02:20:51.342160Z",
     "iopub.status.busy": "2021-11-26T02:20:51.341395Z",
     "iopub.status.idle": "2021-11-26T02:21:50.682760Z",
     "shell.execute_reply": "2021-11-26T02:21:50.683326Z",
     "shell.execute_reply.started": "2021-11-08T05:49:37.075905Z"
    },
    "papermill": {
     "duration": 59.603031,
     "end_time": "2021-11-26T02:21:50.683520",
     "exception": false,
     "start_time": "2021-11-26T02:20:51.080489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| approxkl           | nan      |\n",
      "| clipfrac           | 0.0      |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 4        |\n",
      "| n_updates          | 1        |\n",
      "| policy_entropy     | nan      |\n",
      "| policy_loss        | nan      |\n",
      "| serial_timesteps   | 128      |\n",
      "| time_elapsed       | 2.62e-06 |\n",
      "| total_timesteps    | 128      |\n",
      "| value_loss         | nan      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| approxkl           | nan      |\n",
      "| clipfrac           | 0.0      |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 170      |\n",
      "| n_updates          | 2        |\n",
      "| policy_entropy     | nan      |\n",
      "| policy_loss        | nan      |\n",
      "| serial_timesteps   | 256      |\n",
      "| time_elapsed       | 30.6     |\n",
      "| total_timesteps    | 256      |\n",
      "| value_loss         | nan      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| approxkl           | nan      |\n",
      "| clipfrac           | 0.0      |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 176      |\n",
      "| n_updates          | 3        |\n",
      "| policy_entropy     | nan      |\n",
      "| policy_loss        | nan      |\n",
      "| serial_timesteps   | 384      |\n",
      "| time_elapsed       | 31.3     |\n",
      "| total_timesteps    | 384      |\n",
      "| value_loss         | nan      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| approxkl           | nan      |\n",
      "| clipfrac           | 0.0      |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 178      |\n",
      "| n_updates          | 4        |\n",
      "| policy_entropy     | nan      |\n",
      "| policy_loss        | nan      |\n",
      "| serial_timesteps   | 512      |\n",
      "| time_elapsed       | 32       |\n",
      "| total_timesteps    | 512      |\n",
      "| value_loss         | nan      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| approxkl           | nan      |\n",
      "| clipfrac           | 0.0      |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 175      |\n",
      "| n_updates          | 5        |\n",
      "| policy_entropy     | nan      |\n",
      "| policy_loss        | nan      |\n",
      "| serial_timesteps   | 640      |\n",
      "| time_elapsed       | 32.8     |\n",
      "| total_timesteps    | 640      |\n",
      "| value_loss         | nan      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| approxkl           | nan      |\n",
      "| clipfrac           | 0.0      |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 177      |\n",
      "| n_updates          | 6        |\n",
      "| policy_entropy     | nan      |\n",
      "| policy_loss        | nan      |\n",
      "| serial_timesteps   | 768      |\n",
      "| time_elapsed       | 33.5     |\n",
      "| total_timesteps    | 768      |\n",
      "| value_loss         | nan      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| approxkl           | nan      |\n",
      "| clipfrac           | 0.0      |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 181      |\n",
      "| n_updates          | 7        |\n",
      "| policy_entropy     | nan      |\n",
      "| policy_loss        | nan      |\n",
      "| serial_timesteps   | 896      |\n",
      "| time_elapsed       | 34.2     |\n",
      "| total_timesteps    | 896      |\n",
      "| value_loss         | nan      |\n",
      "---------------------------------\n",
      "Saved model: g_research_ppo_1637893244\n"
     ]
    }
   ],
   "source": [
    "def learn(timesteps=1000):\n",
    "    model = PPO2(MlpLnLstmPolicy, env, verbose=1, nminibatches=1)\n",
    "    model.learn(total_timesteps=timesteps)\n",
    "    model.save(MODEL_ID)\n",
    "    print(f\"Saved model: {MODEL_ID}\")\n",
    "learn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69652c3b",
   "metadata": {
    "papermill": {
     "duration": 0.260165,
     "end_time": "2021-11-26T02:21:51.200966",
     "exception": false,
     "start_time": "2021-11-26T02:21:50.940801",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span class=\"title-section w3-xxlarge\" id=\"submit\">Submit To Kaggle 🇰</span>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "329cdcee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-26T02:21:51.721562Z",
     "iopub.status.busy": "2021-11-26T02:21:51.720427Z",
     "iopub.status.idle": "2021-11-26T02:22:18.270297Z",
     "shell.execute_reply": "2021-11-26T02:22:18.270908Z",
     "shell.execute_reply.started": "2021-11-08T05:52:58.807573Z"
    },
    "papermill": {
     "duration": 26.814979,
     "end_time": "2021-11-26T02:22:18.271386",
     "exception": false,
     "start_time": "2021-11-26T02:21:51.456407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n",
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    }
   ],
   "source": [
    "all_df_test = []\n",
    "\n",
    "predict_df = pd.DataFrame()\n",
    "gr_env = gresearch_crypto.make_env() # initialize the environment\n",
    "iter_test = gr_env.iter_test()       # an iterator which loops over the test set\n",
    "model = PPO2.load(MODEL_ID)\n",
    "for i, (df_test, df_pred) in enumerate(iter_test):\n",
    "    for j, row in df_test.iterrows():\n",
    "        try:                        \n",
    "            row_feats = get_features(row)\n",
    "            predict_df.append(row_feats)\n",
    "            if len(predict_df) > window_size:\n",
    "                obs = np.array([predict_df[idx: idx + window_size][feature].values for feature in features])\n",
    "                action, _states = model.predict(np.expand_dims(obs, axis = 0)) # _states are only useful when using LSTM policies\n",
    "            else: action = 0.0\n",
    "            y_pred = action             \n",
    "        except: \n",
    "            y_pred = 0.0\n",
    "            traceback.print_exc()\n",
    "        df_pred.loc[df_pred['row_id'] == row['row_id'], 'Target'] = y_pred\n",
    "    all_df_test.append(df_test)\n",
    "    gr_env.predict(df_pred)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e39553e",
   "metadata": {
    "papermill": {
     "duration": 0.376417,
     "end_time": "2021-11-26T02:22:19.010270",
     "exception": false,
     "start_time": "2021-11-26T02:22:18.633853",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <span class=\"title-section w3-xxlarge\">References</span>\n",
    "\n",
    "<span id=\"f1\">1.</span> [Initial baseline notebook](https://www.kaggle.com/julian3833)<br>\n",
    "<span id=\"f2\">2.</span> [Competition tutorial](https://www.kaggle.com/cstein06/tutorial-to-the-g-research-crypto-competition)<br>\n",
    "<span id=\"f3\">3.</span> [Competition Overview](https://www.kaggle.com/c/g-research-crypto-forecasting/overview)</span><br>\n",
    "<span id=\"f4\">4.</span> [My Initial Ideas for this competition](https://www.kaggle.com/c/g-research-crypto-forecasting/discussion/284903)</span><br>\n",
    "<span id=\"f5\">5.</span> [My post notebook about cross validation](https://www.kaggle.com/yamqwe/let-s-talk-validation-grouptimeseriessplit)</span><br>\n",
    "<span id=\"f5\">6.</span> [Chris original notebook from SIIM ISIC](https://www.kaggle.com/cdeotte/triple-stratified-kfold-with-tfrecords)</span><br>\n",
    "\n",
    "<span class=\"title-section w3-large w3-tag\">WORK IN PROGRESS! 🚧</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 334.011912,
   "end_time": "2021-11-26T02:22:22.173367",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-26T02:16:48.161455",
   "version": "2.3.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
